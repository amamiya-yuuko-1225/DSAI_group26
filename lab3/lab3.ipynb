{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT565/DIT407 Assignment 3\n",
    "\n",
    "Author: Group 26 | Wenjun Tian wenjunt@chalmers.se | Yifan Tang yifant@chalmers.se\n",
    "\n",
    "Date: 2024-11-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Spam & Ham\n",
    "\n",
    "## A. Data exploration\n",
    "\n",
    "By the judgment as a human being, these following features makes me able to tell spam apart from ham:\n",
    "\n",
    "1. Topic and related key words: Spam emails mostly focus on commodity promotion, dating/porn website promotion, and pure scam. For commodity promotion emails, there are key words related to prices, such as \"$\", \"cash\", and \"cheap\"; for dating/porn website promotion, there are key words concerning sexual features, such as \"amateur\", \"wives\", and \"girls\"; for scam emails, mostly, might focus on topics like unexpected fortune or job opportunities. By contrast, ham emails have various topics, including work-related content, personal communication, and legitimate newsletters.\n",
    "\n",
    "2. Structure of the `HTML` content: Spam emails are usually generated from a fixed template, thus most of them have complex and fancy `HTML` structures. These can include various fonts, colors, and embedded media. On the other hand, ham emails are simple and neat in most cases, which focuses on direct communication.\n",
    "\n",
    "3. Spam markers: Spam emails tend to be marked as AD by mail server admins and users, while ham emails do not. Moreover, spam emails sometimes explicitly assert \"This is NOT spam!\" or something similar, which is a very poor lie that reveals the truth. On the other hand, ham emails lack such markers and are usually consistent in terms of content and senders.\n",
    "\n",
    "Furthermore, the reasons that make hard ham emails different from easy ham emails but similar to spam emails are as follows:\n",
    "\n",
    "1. Similar content to spams: Hard ham emails also focus on promotion of commodities, companies, etc. This makes hard ham emails look like spams, especially in their subject and promotion words.\n",
    "\n",
    "2. Created from templates: Hard ham emails are also created from templates and sent to a large amount of people, which resembles spams in terms of `HTML` structure.\n",
    "\n",
    "Though hard ham emails are hard to distinguish from spams, there is a key feature that differentiates those two: Most hard ham emails have \"unsubcribe\" key word, meaning that the receivers can reject further emailing. However, spam emails rarely provide such function.\n",
    "\n",
    "## B. Data splitting\n",
    "\n",
    "We perform the train-test set split with a ratio of 3:1 by invoking `train_test_split()` function in `sklean.model_selection` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Preprocessing\n",
    "\n",
    "We read email files from specified categories (`easy_ham`, `hard_ham`, and `spam`) and stores their content in a `DataFrame` for further analysis.\n",
    "\n",
    "In the `read_email_file()` function, we try to read the content of an email file using different encodings (ascii, iso-8859-1, and utf-8) to handle potential encoding issues. If one encoding fails, the function attempts the next one, ensuring that most email files can be read without errors.\n",
    "\n",
    "For each email file, the content is read using `read_email_file()` and a dictionary containing the content (`Content`) and its category (`Category`) is created.\n",
    "\n",
    "After reading all email files, we convert the list of dictionaries into a `DataFrame` where each line represents an email file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return-Path: &lt;bounce-lgmedia-2534370@sprocket....</td>\n",
       "      <td>hard_ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Return-Path: &lt;Online#3.19725.55-A8YAgb1NX5rYkd...</td>\n",
       "      <td>hard_ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Return-Path: &lt;Online#3.19592.a8-JNyKlW9O8FdiLs...</td>\n",
       "      <td>hard_ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From bounce-neatnettricks-2424157@silver.lyris...</td>\n",
       "      <td>hard_ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Return-Path: &lt;Online#3.20115.09-rB-TgEkNwY9w6R...</td>\n",
       "      <td>hard_ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>From Alex-09242002-HTML@frugaljoe.330w.com  Th...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>From mando@insiq.us  Mon Aug 26 15:49:52 2002\\...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>Return-Path: ler@lerami.lerctr.org\\nDelivery-D...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>From fholland@bigfoot.com  Wed Sep 11 19:43:52...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>From arnoldm@aol.com  Mon Sep  9 19:31:32 2002...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3302 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content  Category\n",
       "0     Return-Path: <bounce-lgmedia-2534370@sprocket....  hard_ham\n",
       "1     Return-Path: <Online#3.19725.55-A8YAgb1NX5rYkd...  hard_ham\n",
       "2     Return-Path: <Online#3.19592.a8-JNyKlW9O8FdiLs...  hard_ham\n",
       "3     From bounce-neatnettricks-2424157@silver.lyris...  hard_ham\n",
       "4     Return-Path: <Online#3.20115.09-rB-TgEkNwY9w6R...  hard_ham\n",
       "...                                                 ...       ...\n",
       "3297  From Alex-09242002-HTML@frugaljoe.330w.com  Th...      spam\n",
       "3298  From mando@insiq.us  Mon Aug 26 15:49:52 2002\\...      spam\n",
       "3299  Return-Path: ler@lerami.lerctr.org\\nDelivery-D...      spam\n",
       "3300  From fholland@bigfoot.com  Wed Sep 11 19:43:52...      spam\n",
       "3301  From arnoldm@aol.com  Mon Sep  9 19:31:32 2002...      spam\n",
       "\n",
       "[3302 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "description: read email file, return the content\n",
    "param {str} file_path\n",
    "return {str} content of file \n",
    "'''\n",
    "def read_email_file(file_path: str) -> str:\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='ascii') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except UnicodeDecodeError as e:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "                content = f.read()\n",
    "            return content \n",
    "        except UnicodeDecodeError as e:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            return content \n",
    "    \n",
    "categories = [\"easy_ham\", \"hard_ham\", \"spam\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "#read from email files\n",
    "for root, _, files in os.walk(\".\"):\n",
    "    for category in categories:\n",
    "        if category in root:\n",
    "            for f in files:\n",
    "                rows.append({\n",
    "                    \"Content\": read_email_file(os.path.join(root, f)),\n",
    "                    \"Category\": category\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Easy Ham\n",
    "\n",
    "## 3.1 Code logic\n",
    "First, we perform the train-test set split with a ratio of 3:1 by invoking `train_test_split()` function.\n",
    "\n",
    "Then, we use function `analyze()` to train and evaluate models for classifying spam versus ham emails. \n",
    "\n",
    "In this fucntion, it uses `CountVectorizer` to convert email content into bag of words vectors(in the form of `CRS`) and `LabelEncoder` to encode the categories into integers (`easy_ham`, `hard_ham`, `spam`). \n",
    "\n",
    "Note that we apply `fit_transform()` on the training set and only `transform()` on the test set. The `fit()` function is to \"learn\" from the data (e.g., `CountVectorizer.fit()` is to create the dictionary of words). Thus it is only applied on the training set; the `transform()` function is to transform data according to the principles learned from `fit()` (e.g, `CountVectorizer.tranform()` is to transform plain text into bag of words vectors in the form of CRS based on the dictionary learned from `fit()`). Thus it is applied on both training and test set.\n",
    "\n",
    "Then, the function defines `train_and_test` that fits a Naive Bayes classifier (BernoulliNB or MultinomialNB) to the training data and evaluates it on the test set. We `fit()` the training set into the classifier, and then use the classifier to `predict()` the categories of content in the test set. \n",
    "\n",
    "After that we compare and contrast the predicted and actual categories of the test set, computing `accuracy`, `recall`, `precision` and the confusion matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB:\n",
      "accuracy:0.9043250327653998,precision:0.9166666666666666,recall:0.44715447154471544\n",
      "confusion matrix:\n",
      " tp: 55, fn: 68 \n",
      " fp: 5, tn: 635 \n",
      "\n",
      "MultinomialNB:\n",
      "accuracy:0.9672346002621232,precision:0.9803921568627451,recall:0.8130081300813008\n",
      "confusion matrix:\n",
      " tp: 100, fn: 23 \n",
      " fp: 2, tn: 638 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: amamiya-yuuko-1225 1913250675@qq.com\n",
    "Date: 2024-11-19 17:18:58\n",
    "LastEditors: amamiya-yuuko-1225 1913250675@qq.com\n",
    "Description: \n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "'''\n",
    "description: analyze based on \"easy_ham\" for q3 or \"hard_ham\" for q4\n",
    "param {*} df_train: training set\n",
    "param {*} df_test test set\n",
    "param {*} type: \"easy_ham\" for q3 or \"hard_ham\" for q4\n",
    "return {*} no return, but print acc, precision, recall, and confusion matrix\n",
    "'''\n",
    "def analyze(df_train, df_test, type):\n",
    "    \n",
    "    cv = CountVectorizer(); le = LabelEncoder()\n",
    "\n",
    "    X_train, X_test = cv.fit_transform(df_train['Content']), cv.transform(df_test['Content'])\n",
    "    y_train, y_test = le.fit_transform(df_train['Category']), le.transform(df_test['Category'])\n",
    "\n",
    "    '''\n",
    "    description: train and test using specified classifer\n",
    "    param {*} classifier: BernoulliNB or MultinomialNB \n",
    "    param {*} name: name of the classifier\n",
    "    return {*} no return, but print acc, precision, recall, and confusion matrix\n",
    "    '''\n",
    "    def train_and_test(classifier, name):\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        y_test_inv = le.inverse_transform(y_test)\n",
    "        y_pred_inv = le.inverse_transform(y_pred)\n",
    "        tp = ((y_test_inv == 'spam') & (y_pred_inv == 'spam')).sum()\n",
    "        fp = ((y_test_inv == type) & (y_pred_inv == 'spam')).sum()\n",
    "        fn = ((y_test_inv == 'spam') & (y_pred_inv == type)).sum()\n",
    "        tn = ((y_test_inv == type) & (y_pred_inv == type)).sum()\n",
    "        acc = (tp+tn)/(tp+fp+tn+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn) \n",
    "        print(f\"{name}:\\naccuracy:{acc},precision:{precision},recall:{recall}\")\n",
    "        print(f\"confusion matrix:\\n tp: {tp}, fn: {fn} \\n fp: {fp}, tn: {tn} \\n\")\n",
    "\n",
    "    train_and_test(BernoulliNB(), \"BernoulliNB\")\n",
    "\n",
    "    train_and_test(MultinomialNB(), \"MultinomialNB\")\n",
    "\n",
    "# random seed for training and test set split\n",
    "SEED = 1919810\n",
    "\n",
    "# split training and test set\n",
    "df_train, df_test = train_test_split(df[df['Category'].isin(['easy_ham', 'spam'])], random_state=SEED)\n",
    "\n",
    "analyze(df_train, df_test, 'easy_ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Results\n",
    "\n",
    "Thus, the results are as follows:\n",
    "\n",
    "### BernoulliNB\n",
    "accuracy: 0.9043250327653998; precision: 0.9166666666666666; recall: 0.44715447154471544\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "||Pred. pos.|Pred. neg.|Marginal sum|\n",
    "| --- | --- | --- | --- |\n",
    "|Actual pos.|55|68|123|\n",
    "|Actual neg.|5|635|640|\n",
    "|Marginal sum|60|703|\n",
    "### MultinomialNB\n",
    "accuracy: 0.9672346002621232; precision: 0.9803921568627451; recall: 0.8130081300813008\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "||Pred. pos.|Pred. neg.|Marginal sum|\n",
    "| --- | --- | --- | --- |\n",
    "|Actual pos.|100|23|123|\n",
    "|Actual neg.|2|638|640|\n",
    "|Marginal sum|102|661|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Hard Ham\n",
    "## 4.1 Code logic\n",
    "The logic is the same as problem 3, just consider `hard_ham` instead of `easy_ham`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB:\n",
      "accuracy:0.8882978723404256,precision:0.8642857142857143,recall:0.983739837398374\n",
      "confusion matrix:\n",
      " tp: 121, fn: 2 \n",
      " fp: 19, tn: 46 \n",
      "\n",
      "MultinomialNB:\n",
      "accuracy:0.9361702127659575,precision:0.9172932330827067,recall:0.991869918699187\n",
      "confusion matrix:\n",
      " tp: 122, fn: 1 \n",
      " fp: 11, tn: 54 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df[df['Category'].isin(['hard_ham', 'spam'])], random_state=SEED)\n",
    "\n",
    "analyze(df_train, df_test, 'hard_ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 Results\n",
    "\n",
    "Thus, the results are as follows:\n",
    "\n",
    "### BernoulliNB\n",
    "accuracy: 0.8882978723404256\n",
    "; precision: 0.8642857142857143\n",
    "; recall: 0.983739837398374\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "||Pred. pos.|Pred. neg.|Marginal sum|\n",
    "| --- | --- | --- | --- |\n",
    "|Actual pos.|121|2|123|\n",
    "|Actual neg.|19|46|65|\n",
    "|Marginal sum|140|48|\n",
    "### MultinomialNB\n",
    "accuracy: 0.9361702127659575\n",
    "; precision: 0.9172932330827067\n",
    "; recall: 0.991869918699187\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "||Pred. pos.|Pred. neg.|Marginal sum|\n",
    "| --- | --- | --- | --- |\n",
    "|Actual pos.|122|1|123|\n",
    "|Actual neg.|11|54|65|\n",
    "|Marginal sum|133|55|\n",
    "\n",
    "## 4.3 Differences between problem 3 and 4\n",
    "\n",
    "1. Accuracy: The accuracy for both classifiers for `easy_ham` is higher than for `hard_ham`. It is reasonable since `easy_ham` is easier to differentiate from spam, while `hard_ham` often contains promotional content.\n",
    "\n",
    "2. Precision: For `easy_ham`, the precision for both classifiers is quite high. It implys that most emails predictions of spam are correct, while `hard_ham` has lower precision according to confusing content.\n",
    "\n",
    "3. Recall: The recall is much lower for BernoulliNB on `easy_ham`, which means it cannot distinguish the spam email in many times. On the other hand, `hard_ham` shows a higher recall for both classifiers. Overall, the recall classifier for `easy_ham` is lower than for `hard_ham`.\n",
    "\n",
    "4. Confusion Matrix: Both classifiers have a higher value of false positives (FP) for `hard_ham` than for `easy_ham`, indicating that legitimate but promotion emails are often detected as spam by mistake. However, both classifiers have a very low false negative (FN) value, meaning that actual spam emails are almost always correctly identified."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
