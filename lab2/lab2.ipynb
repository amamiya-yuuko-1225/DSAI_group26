{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Scraping house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: amamiya-yuuko-1225 1913250675@qq.com\n",
    "Date: 2024-11-11 11:33:16\n",
    "LastEditors: amamiya-yuuko-1225 1913250675@qq.com\n",
    "Description: \n",
    "'''\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "map_swe_month_to_eng_abbr = {\n",
    "    \"januari\": \"Jan\",\n",
    "    \"februari\": \"Feb\",\n",
    "    \"mars\": \"Mar\",\n",
    "    \"april\": \"Apr\",\n",
    "    \"maj\": \"May\",\n",
    "    \"juni\": \"Jun\",\n",
    "    \"juli\": \"Jul\",\n",
    "    \"augusti\": \"Aug\",\n",
    "    \"september\": \"Sep\",\n",
    "    \"oktober\": \"Oct\",\n",
    "    \"november\": \"Nov\",\n",
    "    \"december\": \"Dec\"\n",
    "}\n",
    "\n",
    "'''\n",
    "description: uniformize date like \"10-Feb-2021\".\n",
    "param {str} s: raw date\n",
    "return {str} formated date\n",
    "'''\n",
    "def uniformize_date(s: str) -> str:\n",
    "    if \" \" not in s: \n",
    "        i = s.rfind('-')\n",
    "        return s[: i + 1] + \"20\" + s[i + 1: ]\n",
    "    else:\n",
    "        ss = s.split(\" \")\n",
    "        return '-'.join([ss[0], map_swe_month_to_eng_abbr[ss[1]], ss[2]])\n",
    "\n",
    "'''\n",
    "description: scrape advertisements from a single html\n",
    "param {str} path of the html file\n",
    "return {pd.DataFrame} a pivot table of advertisements\n",
    "'''\n",
    "def extract_df_from_html(path: str) -> pd.DataFrame:\n",
    "    #Reading the HTML File\n",
    "    with open(path, 'r') as f:\n",
    "        html = f.read()\n",
    "    \n",
    "    #Parsing the HTML    \n",
    "    soup = BeautifulSoup(html, 'html.parser') \n",
    "    \n",
    "    # Initialize an Empty List\n",
    "    ad_s_list = list()    #This line creates an empty list named \"names\"\n",
    "\n",
    "    #iterate all advertisements\n",
    "    for cell in soup.find_all('li',class_='sold-results__normal-hit'):\n",
    "        #store attributes of an ad\n",
    "        ad_dict = {}\n",
    "\n",
    "        raw_date = cell.find(\"span\", class_=\"hcl-label hcl-label--state hcl-label--sold-at\").text.strip().replace(\"Såld \", \"\")\n",
    "        ad_dict[\"Date of sale (dd-m-yyyy)\"] = uniformize_date(raw_date)\n",
    "\n",
    "        ad_dict[\"Address\"] = cell.find(\"h2\", class_=\"sold-property-listing__heading qa-selling-price-title hcl-card__title\").text.strip()\n",
    "\n",
    "        ad_dict[\"Location\"] = cell.find(\"div\", class_=\"sold-property-listing__location\").div.find_all(string=True, recursive=False)[1].replace(' ', '').replace('\\n', '')\n",
    "\n",
    "        area_and_rum = cell.find(\"div\", class_=\"sold-property-listing__subheading sold-property-listing__area\").text.replace(' ', '').replace('\\n', '').split(\"\\u00A0\")\n",
    "        #area_and_rum: ['161+55', 'm²', '5', 'rum']\n",
    "        ad_dict[\"Area (m^2)\"] = area_and_rum[0]\n",
    "        ad_dict[\"No. of rooms\"] = area_and_rum[2] if 'rum' in area_and_rum else 'NaN'\n",
    "\n",
    "        land_area_element = cell.find(\"div\", class_=\"sold-property-listing__land-area\")\n",
    "        ad_dict[\"Area of the plot (m^2)\"] = land_area_element.text.replace(\" \", '').replace('\\n', '').replace('\\xa0', '')[: -6:] if land_area_element != None else \"NaN\"\n",
    "\n",
    "        index_of_slutpris = cell.text.find(\"Slutpris\")\n",
    "        ad_dict[\"Closing price (kr)\"] = cell.text[index_of_slutpris + len(\"Slutpris\"): cell.text.find(\"kr\", index_of_slutpris): ].replace(\" \", '').replace(\"\\u00A0\", '')\n",
    "\n",
    "        ad_s = pd.Series(ad_dict)\n",
    "\n",
    "        ad_s_list.append(ad_s)\n",
    "        \n",
    "    df = pd.concat(ad_s_list, axis = 1) \n",
    "    return df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_DIR = \"/home/amamiya/dsai/lab2/kungalv_slutpriser\"\n",
    "\n",
    "df_list = []\n",
    "\n",
    "#iterate all html files, scrape and combine data\n",
    "for root, _, files in os.walk(DATA_DIR):\n",
    "    for f in files:\n",
    "        df = extract_df_from_html(os.path.join(root, f))\n",
    "        df_list.append(df)\n",
    "       \n",
    "data = pd.concat(df_list)\n",
    "\n",
    "data.to_csv(\"data.csv\", index=None, encoding=\"UTF-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
